import streamlit as st
from PIL import Image
import io, os
import yaml
import numpy as np

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –∫–æ–Ω—Ñ–∏–≥ ---
CONFIG_FILE = "config.yaml"
DEFAULT_CONFIG = {
    "output_dir": "covers_output",
    "blend_mode": "overlay",
    "opacity": 24,
    "texture_path": None
}

# –ó–∞–≥—Ä—É–∑–∫–∞/–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥–∞
def load_config():
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, "r") as f:
            return yaml.safe_load(f) or DEFAULT_CONFIG.copy()
    else:
        with open(CONFIG_FILE, "w") as f:
            yaml.safe_dump(DEFAULT_CONFIG, f)
        return DEFAULT_CONFIG.copy()

config = load_config()

def save_config():
    with open(CONFIG_FILE, "w") as f:
        yaml.safe_dump(config, f)

# --- UI Streamlit ---
st.set_page_config(page_title="Batch Cover Matcher", layout="wide")
st.title("üéß Batch Cover Matcher for EDM Covers")

# Sidebar settings
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

    # Texture loading or existing texture
    texture = None
    if config.get("texture_path") and os.path.exists(config["texture_path"]):
        st.text("–¢–µ–∫—É—â–∞—è —Ç–µ–∫—Å—Ç—É—Ä–∞:")
        st.image(config["texture_path"], width=100)
        if st.button("–ó–∞–º–µ–Ω–∏—Ç—å —Ç–µ–∫—Å—Ç—É—Ä—É"):
            config["texture_path"] = None
            save_config()
        else:
            texture = config["texture_path"]
    if texture is None:
        uploaded_tex = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ–∫—Å—Ç—É—Ä—É (PNG/JPG)", type=["png","jpg","jpeg"])
        if uploaded_tex:
            os.makedirs("textures", exist_ok=True)
            path = os.path.join("textures", uploaded_tex.name)
            with open(path, "wb") as f:
                f.write(uploaded_tex.read())
            config["texture_path"] = path
            save_config()
            texture = path

    # Blend mode and opacity
    config["blend_mode"] = st.selectbox(
        "–†–µ–∂–∏–º –Ω–∞–ª–æ–∂–µ–Ω–∏—è",
        ["overlay","multiply","screen"],
        index=["overlay","multiply","screen"].index(config.get("blend_mode","overlay"))
    )
    config["opacity"] = st.slider("–ù–µ–ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å (%)", 0, 100, config.get("opacity",24))

    # Output directory
    st.markdown("---")
    dirs = [d for d in os.listdir() if os.path.isdir(d)]
    dirs.insert(0, "<–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é>")
    sel = st.selectbox("–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è", dirs,
                       index=dirs.index(config.get("output_dir")) if config.get("output_dir") in dirs else 0)
    if sel == "<–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é>":
        config["output_dir"] = st.text_input("–ò–º—è –Ω–æ–≤–æ–π –ø–∞–ø–∫–∏", value=config.get("output_dir"))
    else:
        config["output_dir"] = sel

    save_config()

# 1) –ó–∞–≥—Ä—É–∑–∫–∞ WAV-—Ñ–∞–π–ª–æ–≤
wavs = st.file_uploader("1) –ó–∞–≥—Ä—É–∑–∏—Ç–µ WAV-—Ñ–∞–π–ª—ã", type=["wav"], accept_multiple_files=True)
if not wavs:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ WAV-—Ñ–∞–π–ª—ã –¥–ª—è –Ω–∞—á–∞–ª–∞")
    st.stop()

# 2) –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±–ª–æ–∂–µ–∫
st.subheader("2) –î–æ–±–∞–≤—å—Ç–µ –æ–±–ª–æ–∂–∫–∏ –∫ —Ç—Ä–µ–∫–∞–º")
cover_data = {}
for wav in wavs:
    with st.expander(wav.name, expanded=False):
        f = st.file_uploader(f"–û–±–ª–æ–∂–∫–∞ –¥–ª—è {wav.name}", type=["png","jpg","jpeg"], key=wav.name)
        if f:
            data = f.read()
            img = Image.open(io.BytesIO(data))
            st.image(img, width=120)
            cover_data[wav.name] = data

# 3) –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
if st.button("‚ñ∂Ô∏è Run"):
    missing = [w.name for w in wavs if w.name not in cover_data]
    if missing:
        st.error(f"–ù–µ—Ç –æ–±–ª–æ–∂–µ–∫ –¥–ª—è: {', '.join(missing)}")
        st.stop()

    out_dir = config["output_dir"]
    os.makedirs(out_dir, exist_ok=True)
    TARGET = 3000

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç—É—Ä—ã
    texture_arr = None
    if config.get("texture_path"):
        tex_img = Image.open(config["texture_path"]).convert("RGB").resize((TARGET, TARGET), Image.LANCZOS)
        texture_arr = np.array(tex_img).astype(np.float32)

    results = []
    for wav in wavs:
        base = os.path.splitext(wav.name)[0]
        img = Image.open(io.BytesIO(cover_data[wav.name])).convert("RGB")
        # Resize & center crop
        w, h = img.size
        scale = max(TARGET/w, TARGET/h)
        img = img.resize((int(w*scale), int(h*scale)), Image.LANCZOS)
        w2, h2 = img.size
        left, top = (w2 - TARGET)//2, (h2 - TARGET)//2
        img = img.crop((left, top, left+TARGET, top+TARGET))

        # Blending with texture
        if texture_arr is not None:
            base_arr = np.array(img).astype(np.float32)
            # select blend mode
            if config["blend_mode"] == "overlay":
                mask = base_arr <= 128
                blended = np.zeros_like(base_arr)
                blended[mask] = (2 * base_arr[mask] * texture_arr[mask] / 255)
                blended[~mask] = (255 - 2 * (255 - base_arr[~mask]) * (255 - texture_arr[~mask]) / 255)
            elif config["blend_mode"] == "multiply":
                blended = base_arr * texture_arr / 255
            else:  # screen
                blended = 255 - (255 - base_arr) * (255 - texture_arr) / 255
            alpha = config["opacity"] / 100.0
            result_arr = (1 - alpha) * base_arr + alpha * blended
            result_arr = np.clip(result_arr, 0, 255).astype(np.uint8)
            img = Image.fromarray(result_arr)

        out_path = os.path.join(out_dir, f"{base}.png")
        img.save(out_path)
        results.append(out_path)

    st.success(f"–ì–æ—Ç–æ–≤–æ! –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(results)} –æ–±–ª–æ–∂–µ–∫ –≤ '{out_dir}'")
    st.write(results)